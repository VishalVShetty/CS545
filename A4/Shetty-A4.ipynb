{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Convolutional-Neural-Networks\" data-toc-modified-id=\"Convolutional-Neural-Networks-1\">Convolutional Neural Networks</a></span><ul class=\"toc-item\"><li><span><a href=\"#Requirements\" data-toc-modified-id=\"Requirements-1.1\">Requirements</a></span></li></ul></li><li><span><a href=\"#Experiments\" data-toc-modified-id=\"Experiments-2\">Experiments</a></span></li><li><span><a href=\"#Grading\" data-toc-modified-id=\"Grading-3\">Grading</a></span></li><li><span><a href=\"#Extra-Credit\" data-toc-modified-id=\"Extra-Credit-4\">Extra Credit</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "For this assignment, use the `NeuralNetworkClassifier_CNN` class defined for you in `neuralnetworks_A4.py` contained in [A4code.tar](https://www.cs.colostate.edu/~anderson/cs545/notebooks/A4code.tar).  This tar file also includes other functions you will use here, contained in `mlfuncs.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T23:41:20.815440Z",
     "start_time": "2021-10-15T23:41:20.802779Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T23:41:21.563150Z",
     "start_time": "2021-10-15T23:41:21.349591Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import itertools\n",
    "%matplotlib inline\n",
    "\n",
    "import neuralnetworks_A4 as nn\n",
    "import mlfuncs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, look carefully at the `neuralnetworks_A4.py` and `optimizers.py` code provided above.  Some changes have been made in each. The most significant change is that the `train` function now accepts a `batch_size` argument so that the gradients we calculate don't have to be over the whole training set.  Recall that we can easily run out of memory with convolutional networks if we calculate gradients over the whole training set.  Also, `'scg'` is not a valid optimizer in this version of the code.\n",
    "\n",
    "Implement the following functions:\n",
    "\n",
    "    dataframe_result = run_these_parameters(X, T, n_folds,\n",
    "                                            layers_structs, \n",
    "                                            methods, \n",
    "                                            epochs, \n",
    "                                            learning_rates.\n",
    "                                            batch_sizes)\n",
    "                                              \n",
    "    result = train_this_partition(Xtrain, Ttrain, Xval, Tval, Xtest, Ttest,\n",
    "                                  struct,\n",
    "                                  n_epochs, \n",
    "                                  method, \n",
    "                                  learning_rate,\n",
    "                                  batch_size)\n",
    "                                  \n",
    "The file `mlfuncs.py` contains several functions you will need to define these two required functions.  They are illustrated in the following examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T23:41:22.456416Z",
     "start_time": "2021-10-15T23:41:22.440139Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.array([0, 1, 1, 0, 0]).reshape(-1, 1)\n",
    "T = np.array([0, 1, 0, 1, 0]).reshape(-1, 1)\n",
    "mlfuncs.percent_equal(Y, T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of that one is obvious.  This next one is needed for storing your network stucture in a pandas DataFrame.  The structure must be an immutable data type.  A list is mutable, but a tuple is not.  So we must make sure all parts of the network structure specification is composed of tuples, not lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T23:41:23.819633Z",
     "start_time": "2021-10-15T23:41:23.811752Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((), (10,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct = [ [], [10]]\n",
    "mlfuncs.list_to_tuple(struct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T23:41:24.071779Z",
     "start_time": "2021-10-15T23:41:24.047492Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((2, 4, 1), (5, 4, 2)), (20, 10))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct = [ [[2, 4, 1], [5, 4, 2]], [20, 10]]\n",
    "mlfuncs.list_to_tuple(struct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is a function that generates all training, validation, and testing partitions given the data and the number of folds.  It creates the partitions in a stratified manner, meaning all folds will have close to the same proportion of samples from each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T23:41:24.546767Z",
     "start_time": "2021-10-15T23:41:24.537570Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0,  1],\n",
       "        [ 2,  3],\n",
       "        [ 4,  5],\n",
       "        [ 6,  7],\n",
       "        [ 8,  9],\n",
       "        [10, 11]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.arange(12).reshape(6, 2)\n",
    "T = np.array([0, 0, 1, 0, 1, 1]).reshape(-1, 1)\n",
    "X, T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T23:41:25.607634Z",
     "start_time": "2021-10-15T23:41:25.592463Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [8 9]] \n",
      " [[0]\n",
      " [1]] \n",
      " [[6 7]\n",
      " [4 5]] \n",
      " [[0]\n",
      " [1]] \n",
      " [[ 2  3]\n",
      " [10 11]] \n",
      " [[0]\n",
      " [1]]\n",
      "\n",
      "[[6 7]\n",
      " [4 5]] \n",
      " [[0]\n",
      " [1]] \n",
      " [[0 1]\n",
      " [8 9]] \n",
      " [[0]\n",
      " [1]] \n",
      " [[ 2  3]\n",
      " [10 11]] \n",
      " [[0]\n",
      " [1]]\n",
      "\n",
      "[[0 1]\n",
      " [8 9]] \n",
      " [[0]\n",
      " [1]] \n",
      " [[ 2  3]\n",
      " [10 11]] \n",
      " [[0]\n",
      " [1]] \n",
      " [[6 7]\n",
      " [4 5]] \n",
      " [[0]\n",
      " [1]]\n",
      "\n",
      "[[ 2  3]\n",
      " [10 11]] \n",
      " [[0]\n",
      " [1]] \n",
      " [[0 1]\n",
      " [8 9]] \n",
      " [[0]\n",
      " [1]] \n",
      " [[6 7]\n",
      " [4 5]] \n",
      " [[0]\n",
      " [1]]\n",
      "\n",
      "[[6 7]\n",
      " [4 5]] \n",
      " [[0]\n",
      " [1]] \n",
      " [[ 2  3]\n",
      " [10 11]] \n",
      " [[0]\n",
      " [1]] \n",
      " [[0 1]\n",
      " [8 9]] \n",
      " [[0]\n",
      " [1]]\n",
      "\n",
      "[[ 2  3]\n",
      " [10 11]] \n",
      " [[0]\n",
      " [1]] \n",
      " [[6 7]\n",
      " [4 5]] \n",
      " [[0]\n",
      " [1]] \n",
      " [[0 1]\n",
      " [8 9]] \n",
      " [[0]\n",
      " [1]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for Xtrain, Ttrain, Xval, Tval, Xtest, Ttest in mlfuncs.generate_partitions(X, T, n_folds=3, classification=True):\n",
    "        print(Xtrain, '\\n', Ttrain, '\\n', Xval, '\\n', Tval, '\\n', Xtest, '\\n', Ttest)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `run_these_parameters` loops through all values in `layers_structs`, `methods`, `epochs`, `learning rates` and `batch_sizes`.  For each set of parameter values, it loops through all ways of creating training, validation, and testing partitions using `n_folds`.  For each of these repetitions, `train_this_partition` is called to create the specified convolutional neural network, trains it, collects the percent correct on training, validation, and test sets, and returns a list of parameter values and the three accuracies.  `run_these_parameters` returns all of these results as a `pandas` DataFrame with column names `('struct', 'method', 'n_epochs', 'learning_rate', 'batch_size', 'train %', 'val %', 'test %')`. \n",
    "\n",
    "The resulting DataFrame results stored in variable `df` can be summarized with a statement like\n",
    "\n",
    "      df.groupby(['struct', 'method', 'n_epochs', 'learning_rate',\n",
    "                  'batch_size']).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ru_these_parameter\n",
    "#FIXED\n",
    "def run_these_parameters(X, T, n_folds,\n",
    "                         structs,\n",
    "                          methods,\n",
    "                          epochs,\n",
    "                          learning_rates,\n",
    "                          batch_sizes):\n",
    "    column_names = ('structs','methods','epochs','learning_rates','batch_sizes')\n",
    "    result = pd.DataFrame((itertools.product(structs,methods,epochs,learning_rates,batch_sizes)),columns = column_names)\n",
    "    #print(result)\n",
    "    percent_trains = []\n",
    "    percent_vals = []\n",
    "    percent_tests = []\n",
    "    new_result = pd.DataFrame(columns = ['structs','methods','epochs','learning_rates','batch_sizes','train %','val %','test %'])\n",
    "    for i,valuepassing in result.iterrows():\n",
    "            for Xtrain, Ttrain,Xval,Tval, Xtest, Ttest in mlfuncs.generate_partitions(X, T, n_folds, validation=True, shuffle=True, classification=True):\n",
    "                struct = valuepassing['structs']\n",
    "                n_epochs = valuepassing['epochs']\n",
    "                method = valuepassing['methods']\n",
    "                learning_rate = valuepassing['learning_rates']\n",
    "                batch_size = valuepassing['batch_sizes']\n",
    "                temp_list = train_this_partition(Xtrain, Ttrain, Xval, Tval, Xtest, Ttest,struct, n_epochs, method, learning_rate, batch_size)\n",
    "                percent_train = (temp_list[-3])\n",
    "                percent_val = (temp_list[-2])\n",
    "                percent_test = (temp_list[-1])\n",
    "                temp_list_2 = [[struct,method,n_epochs,learning_rate,batch_size,percent_train,percent_val,percent_test]]\n",
    "                #new_result = new_result.append(temp_list_2,ignore_index=True)\n",
    "                new_result = new_result.append(pd.DataFrame(temp_list_2, columns=['structs','methods','epochs','learning_rates','batch_sizes','train %','val %','test %']), ignore_index=True)\n",
    "    return new_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_this_partition(Xtrain, Ttrain, Xval, Tval, Xtest, Ttest,\n",
    "                              struct, n_epochs, method, learning_rate, batch_size):\n",
    "    #print(struct, n_epochs, method, learning_rate, batch_size)\n",
    "    results = []\n",
    "    classes = np.unique(Ttrain)\n",
    "    cnn = nn.NeuralNetworkClassifier_CNN(Xtrain[1].shape,struct[0],struct[1], classes)\n",
    "    #print(cnn)\n",
    "    cnn.train( Xtrain, Ttrain, n_epochs, method, learning_rate, momentum=0.1, batch_size=None, verbose=False)\n",
    "    Ytrain,_ = cnn.use(Xtrain)\n",
    "    Yval,_ = cnn.use(Xval)\n",
    "    Ytest,_ = cnn.use(Xtest)\n",
    "    #print(Ytrain,Ttrain)\n",
    "    percent_train = mlfuncs.percent_equal(Ytrain, Ttrain)\n",
    "    percent_val = mlfuncs.percent_equal(Yval, Tval)\n",
    "    percent_test = mlfuncs.percent_equal(Ytest, Ttest)\n",
    "    return [mlfuncs.list_to_tuple(struct), method, n_epochs, learning_rate,batch_size,percent_train,percent_val,percent_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the two required functions in code cells above this cell.\n",
    "\n",
    "The following examples show examples of how they should run, as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T23:41:31.175012Z",
     "start_time": "2021-10-15T23:41:30.389530Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 40 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def make_images(n_each_class):\n",
    "    '''Make 20x20 black and white images with diamonds or squares for the two classes, as line drawings.'''\n",
    "    images = np.zeros((n_each_class * 4, 20, 20))  # nSamples, rows, columns\n",
    "    radii = 3 + np.random.randint(10 - 5, size=(n_each_class * 4, 1))\n",
    "    centers = np.zeros((n_each_class * 4, 2))\n",
    "    for i in range(n_each_class * 4):\n",
    "        r = radii[i, 0]\n",
    "        centers[i, :] = r + 1 + np.random.randint(18 - 2 * r, size=(1, 2))\n",
    "        x = int(centers[i, 0])\n",
    "        y = int(centers[i, 1])\n",
    "        if i < n_each_class:\n",
    "            # plus\n",
    "            images[i, x - r:x + r, y] = 1.0\n",
    "            images[i, x, y - r:y + r] = 1.0\n",
    "        elif i < n_each_class * 2:\n",
    "            # minus\n",
    "            images[i, x, y - r:y + r] = 1.0\n",
    "        elif i < n_each_class * 3:\n",
    "            # x\n",
    "            images[i, range(x - r, x + r), range(y - r, y + r)] = 1.0\n",
    "            images[i, range(x - r, x + r), range(y + r, y - r, -1)] = 1.0\n",
    "        else:\n",
    "            # /\n",
    "            images[i, range(x - r, x + r), range(y - r, y + r)] = 1.0\n",
    "\n",
    "    T = np.array(['plus'] * n_each_class + ['minus'] * n_each_class + ['times'] * n_each_class + ['divide'] * n_each_class).reshape(-1, 1)\n",
    "\n",
    "    n, r, c = images.shape\n",
    "    images = images.reshape(n, r, c, 1)  # add channel dimsension\n",
    "    return images, T\n",
    "\n",
    "n_each_class = 10\n",
    "X, T = make_images(n_each_class)\n",
    "p = 0\n",
    "for i in range(4 * n_each_class):\n",
    "    p += 1\n",
    "    plt.subplot(4, n_each_class, p)\n",
    "    plt.imshow(-X[i, :, :, 0], cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T23:41:32.073364Z",
     "start_time": "2021-10-15T23:41:32.019274Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 20, 20, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_each_class = 500\n",
    "X, T = make_images(n_each_class)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T23:41:35.853124Z",
     "start_time": "2021-10-15T23:41:35.643931Z"
    }
   },
   "outputs": [],
   "source": [
    "# from A4mysolution import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T23:41:37.163016Z",
     "start_time": "2021-10-15T23:41:36.195032Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(((2, 5, 1),), (5,)), 'adam', 10, 0.01, 10, 77.34375, 81.25, 62.5]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct = [ [[2, 5, 1]], [5] ]\n",
    "n_epochs = 10\n",
    "method= 'adam'\n",
    "learning_rate = 0.01\n",
    "batch_size = 10\n",
    "\n",
    "n_samples = X.shape[0]\n",
    "rows = np.arange(n_samples)\n",
    "np.random.shuffle(rows)\n",
    "ntrain = int(n_samples * 0.8)\n",
    "nval = int(n_samples * 0.1)\n",
    "Xtrain = X[rows[:ntrain], ...]\n",
    "Ttrain = T[rows[:ntrain], ...]\n",
    "Xval = X[rows[ntrain:ntrain+nval], ...]\n",
    "Tval = T[rows[ntrain:ntrain+nval], ...]\n",
    "Xtest = X[rows[ntrain+nval:], ...]\n",
    "Ttest = T[rows[ntrain+nval:], ...]         \n",
    "#print(np.unique(Ttrain))\n",
    "result = train_this_partition(Xtrain, Ttrain, Xval, Tval, Xtest, Ttest,\n",
    "                              struct, n_epochs, method, learning_rate, batch_size)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T23:44:04.708062Z",
     "start_time": "2021-10-15T23:42:36.475008Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>structs</th>\n",
       "      <th>methods</th>\n",
       "      <th>epochs</th>\n",
       "      <th>learning_rates</th>\n",
       "      <th>batch_sizes</th>\n",
       "      <th>train %</th>\n",
       "      <th>val %</th>\n",
       "      <th>test %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[5, 3, 1]], []]</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-1</td>\n",
       "      <td>92.50</td>\n",
       "      <td>77.5</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[5, 3, 1]], []]</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-1</td>\n",
       "      <td>95.00</td>\n",
       "      <td>80.0</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[5, 3, 1]], []]</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-1</td>\n",
       "      <td>97.50</td>\n",
       "      <td>85.0</td>\n",
       "      <td>82.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[5, 3, 1]], []]</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-1</td>\n",
       "      <td>98.75</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[5, 3, 1]], []]</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-1</td>\n",
       "      <td>98.75</td>\n",
       "      <td>82.5</td>\n",
       "      <td>82.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>[[[5, 3, 1]], []]</td>\n",
       "      <td>adam</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>100.00</td>\n",
       "      <td>85.0</td>\n",
       "      <td>87.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>[[[5, 3, 1]], []]</td>\n",
       "      <td>adam</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>100.00</td>\n",
       "      <td>75.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>[[[5, 3, 1]], []]</td>\n",
       "      <td>adam</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>100.00</td>\n",
       "      <td>75.0</td>\n",
       "      <td>77.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>[[[5, 3, 1]], []]</td>\n",
       "      <td>adam</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>100.00</td>\n",
       "      <td>77.5</td>\n",
       "      <td>72.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>[[[5, 3, 1]], []]</td>\n",
       "      <td>adam</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>100.00</td>\n",
       "      <td>92.5</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              structs methods epochs  learning_rates batch_sizes  train %  \\\n",
       "0   [[[5, 3, 1]], []]    adam     10            0.01          -1    92.50   \n",
       "1   [[[5, 3, 1]], []]    adam     10            0.01          -1    95.00   \n",
       "2   [[[5, 3, 1]], []]    adam     10            0.01          -1    97.50   \n",
       "3   [[[5, 3, 1]], []]    adam     10            0.01          -1    98.75   \n",
       "4   [[[5, 3, 1]], []]    adam     10            0.01          -1    98.75   \n",
       "..                ...     ...    ...             ...         ...      ...   \n",
       "91  [[[5, 3, 1]], []]    adam     20            0.01         100   100.00   \n",
       "92  [[[5, 3, 1]], []]    adam     20            0.01         100   100.00   \n",
       "93  [[[5, 3, 1]], []]    adam     20            0.01         100   100.00   \n",
       "94  [[[5, 3, 1]], []]    adam     20            0.01         100   100.00   \n",
       "95  [[[5, 3, 1]], []]    adam     20            0.01         100   100.00   \n",
       "\n",
       "    val %  test %  \n",
       "0    77.5    75.0  \n",
       "1    80.0    85.0  \n",
       "2    85.0    82.5  \n",
       "3    80.0    77.5  \n",
       "4    82.5    82.5  \n",
       "..    ...     ...  \n",
       "91   85.0    87.5  \n",
       "92   75.0    90.0  \n",
       "93   75.0    77.5  \n",
       "94   77.5    72.5  \n",
       "95   92.5    85.0  \n",
       "\n",
       "[96 rows x 8 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = run_these_parameters(X, T, n_folds=4,\n",
    "                         structs=[\n",
    "                             # [ [], [] ],\n",
    "                             # [ [], [10] ],\n",
    "                             [[[5, 3, 1]], []],\n",
    "                             # [[[20, 3, 2], [5, 3, 1]], [20]],\n",
    "                            ],\n",
    "                          methods=['adam'], # , 'sgd'],\n",
    "                          epochs=[10, 20],\n",
    "                          learning_rates=[0.01], #, 0.1],\n",
    "                          batch_sizes=[-1, 10, 50, 100])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "\n",
    "When you have `train_this_partition` and `run_these_parameters`, use them to explore the parameter values, trying to find combinations of parameter values that result in high validation accuracies.  \n",
    "\n",
    "Start with one value for each of the five parameters, but remember to specifiy them as a list of one element, like `learning_rates=[0.01]`.  Then run again with 3 or 4 values for one parameter.  Note the best value.  Use that value for that parameter, then add more values for a different parameter.  \n",
    "\n",
    "Proceed this way for each of the parameter values.  Discuss what you observe after each call to `run_these_parameters` with at least two sentences for each run.  Do the parameter values you find that work best surprise you?  Also discuss how well the validation and test accuracies equal each other.\n",
    "\n",
    "For each method, try various hidden layer structures, learning rates, and numbers of epochs.  Use the validation percent accuracy to pick the best hidden layers, learning rates and numbers of epochs for each method.  Report training, validation and test accuracy for your best validation results for each of the three methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimentation Begins From the Cell Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 40 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_each_class = 10\n",
    "X, T = make_images(n_each_class)\n",
    "p = 0\n",
    "for i in range(4 * n_each_class):\n",
    "    p += 1\n",
    "    plt.subplot(4, n_each_class, p)\n",
    "    plt.imshow(-X[i, :, :, 0], cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 20, 20, 1)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_each_class = 500\n",
    "X, T = make_images(n_each_class)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Begining with the structure of the layer of neural network and keeping others as constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After very run we print the Maximum Percentage validation and Layerinfo for that validation percentage\n",
      "Maximum value for Percent_Validation is 81.2\n",
      "Neural Network parameters for maximum percentage validation\n",
      "structs           [[], []]\n",
      "methods               adam\n",
      "epochs                  10\n",
      "learning_rates        0.01\n",
      "batch_sizes             10\n",
      "train %               83.2\n",
      "val %                 81.2\n",
      "Name: 0, dtype: object\n",
      "We are excluding the test percentage so as to avoid peeking\n"
     ]
    }
   ],
   "source": [
    "df = run_these_parameters(X, T, n_folds=4,\n",
    "                         structs=[\n",
    "                             [ [], [] ],\n",
    "                             #[ [], [10] ],\n",
    "                             #[[[10, 3, 1]], []],\n",
    "                             #[[[20, 3, 2], [5, 3, 1]], [20]],\n",
    "                            ],\n",
    "                          methods=['adam'], # , 'sgd'],\n",
    "                          epochs=[10],\n",
    "                          learning_rates=[0.01], #, 0.1],\n",
    "                          batch_sizes=[10])\n",
    "print(\"After very run we print the Maximum Percentage validation and Layerinfo for that validation percentage\")\n",
    "MaxValidation = df.max()['val %']\n",
    "print(\"Maximum value for Percent_Validation is\",MaxValidation)\n",
    "MaxvalueIndex = []\n",
    "MaxvalueIndex = df['val %'].argmax()\n",
    "Layerinfo1 = df.iloc[MaxvalueIndex]\n",
    "print('Neural Network parameters for maximum percentage validation')\n",
    "print(Layerinfo1[0:7])\n",
    "print(\"We are excluding the test percentage so as to avoid peeking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion : \n",
    "1. Starting with a simple linear model .i.e. with no convolution layer and no fully connected layer we get a lower percentage validation.\n",
    "2. Even with lower value of number of epochs we get a significantly higher value of validation percentage.\n",
    "3. The lower value of learning rate also significantly contributes to the lower value of training percentage, due to hunting for a better local minima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After very run we print the Maximum Percentage validation and Layerinfo for that validation percentage\n",
      "Maximum value for Percent_Validation is 79.2\n",
      "Neural Network parameters for maximum percentage validation\n",
      "structs           [[], []]\n",
      "methods               adam\n",
      "epochs                  10\n",
      "learning_rates        0.01\n",
      "batch_sizes             10\n",
      "train %               81.6\n",
      "val %                 79.2\n",
      "Name: 7, dtype: object\n",
      "We are excluding the test percentage so as to avoid peeking\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    df = run_these_parameters(X, T, n_folds=4,\n",
    "                         structs=[\n",
    "                             [ [], [] ],\n",
    "                             [ [], [10] ],\n",
    "                             [[[10, 3, 1]], []],\n",
    "                             [[[20, 3, 2], [5, 3, 1]], [15]],\n",
    "                            ],\n",
    "                          methods=['adam'], # , 'sgd'],\n",
    "                          epochs=[10],\n",
    "                          learning_rates=[0.01], #, 0.1],\n",
    "                          batch_sizes=[10])\n",
    "    print(\"After very run we print the Maximum Percentage validation and Layerinfo for that validation percentage\")\n",
    "    MaxValidation = df.max()['val %']\n",
    "    print(\"Maximum value for Percent_Validation is\",MaxValidation)\n",
    "    MaxvalueIndex = []\n",
    "    MaxvalueIndex = df['val %'].argmax()\n",
    "    Layerinfo2 = df.iloc[MaxvalueIndex]\n",
    "    print('Neural Network parameters for maximum percentage validation')\n",
    "    print(Layerinfo2[0:7])\n",
    "    print(\"We are excluding the test percentage so as to avoid peeking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion : \n",
    "1. Here we get a slightly better validation percentage without overfitting the training data with all the outcomes.\n",
    "2. A convolutional layer does improve the performance of a network, even with a low training percentage.\n",
    "3. We get an almost identical value for percent validation and percent training.\n",
    "4. Here we get a best value for the structure of the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Now keeping neural network layer fixed we vary learning rate, and keep other paramters as constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After very run we print the Maximum Percentage validation and Layerinfo for that validation percentage\n",
      "Maximum value for Percent_Validation is 73.2\n",
      "Neural Network parameters for maximum percentage validation\n",
      "structs           [[[10, 3, 1]], []]\n",
      "methods                         adam\n",
      "epochs                            10\n",
      "learning_rates                  0.01\n",
      "batch_sizes                       10\n",
      "train %                         72.7\n",
      "val %                           73.2\n",
      "Name: 0, dtype: object\n",
      "We are excluding the test percentage so as to avoid peeking\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    df = run_these_parameters(X, T, n_folds=4,\n",
    "                         structs=[\n",
    "                             #[ [], [] ],\n",
    "                             #[ [], [10] ],\n",
    "                             [[[10, 3, 1]], []],\n",
    "                             #[[[20, 3, 2], [5, 3, 1]], [15]],\n",
    "                             #[[[8, 4, 1]], [10],[5]],\n",
    "                            ],\n",
    "                          methods=['adam'], # , 'sgd'],\n",
    "                          epochs=[10],\n",
    "                          learning_rates=[0.01], #, 0.1],\n",
    "                          batch_sizes=[10])\n",
    "    print(\"After very run we print the Maximum Percentage validation and Layerinfo for that validation percentage\")\n",
    "    MaxValidation = df.max()['val %']\n",
    "    print(\"Maximum value for Percent_Validation is\",MaxValidation)\n",
    "    MaxvalueIndex = []\n",
    "    MaxvalueIndex = df['val %'].argmax()\n",
    "    Layerinfo3 = df.iloc[MaxvalueIndex]\n",
    "    print('Neural Network parameters for maximum percentage validation')\n",
    "    print(Layerinfo3[0:7])\n",
    "    print(\"We are excluding the test percentage so as to avoid peeking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions:\n",
    "1. With a learning rate of 0.01 we get a lower validation here than in the previous example.\n",
    "2. A significant drop in validation percentage is seen even though training percentage is almost same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After very run we print the Maximum Percentage validation and Layerinfo for that validation percentage\n",
      "Maximum value for Percent_Validation is 80.60000000000001\n",
      "Neural Network parameters for maximum percentage validation\n",
      "structs           [[[10, 3, 1]], []]\n",
      "methods                         adam\n",
      "epochs                            10\n",
      "learning_rates                 0.009\n",
      "batch_sizes                       10\n",
      "train %                         79.8\n",
      "val %                           80.6\n",
      "Name: 33, dtype: object\n",
      "We are excluding the test percentage so as to avoid peeking\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    df = run_these_parameters(X, T, n_folds=4,\n",
    "                         structs=[\n",
    "                             #[ [], [] ],\n",
    "                             #[ [], [10] ],\n",
    "                             [[[10, 3, 1]], []],\n",
    "                             #[[[20, 3, 2], [5, 3, 1]], [15]],\n",
    "                             #[[[8, 4, 1]], [10],[5]],\n",
    "                            ],\n",
    "                          methods=['adam'], # , 'sgd'],\n",
    "                          epochs=[10],\n",
    "                          learning_rates=[0.0001,0.005,0.009,0.01,0.07,0.1], #, 0.1],\n",
    "                          batch_sizes=[10])\n",
    "    print(\"After very run we print the Maximum Percentage validation and Layerinfo for that validation percentage\")\n",
    "    MaxValidation = df.max()['val %']\n",
    "    print(\"Maximum value for Percent_Validation is\",MaxValidation)\n",
    "    MaxvalueIndex = []\n",
    "    MaxvalueIndex = df['val %'].argmax()\n",
    "    Layerinfo4 = df.iloc[MaxvalueIndex]\n",
    "    print('Neural Network parameters for maximum percentage validation')\n",
    "    print(Layerinfo4[0:7])\n",
    "    print(\"We are excluding the test percentage so as to avoid peeking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion : \n",
    "1. At a lower value of learning_rate, percentage validation increases without any significant increase in training percentage,  2. A lower value of learning_rate does significantly increase the risk of the neural network hunting for a better local minima, which could lead to worse results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Fixing neural net layer and learning_rate we now change method and keep others constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After very run we print the Maximum Percentage validation and Layerinfo for that validation percentage\n",
      "Maximum value for Percent_Validation is 81.39999999999999\n",
      "Neural Network parameters for maximum percentage validation\n",
      "structs           [[[10, 3, 1]], []]\n",
      "methods                         adam\n",
      "epochs                            10\n",
      "learning_rates                 0.005\n",
      "batch_sizes                       10\n",
      "train %                         82.5\n",
      "val %                           81.4\n",
      "Name: 6, dtype: object\n",
      "We are excluding the test percentage so as to avoid peeking\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    df = run_these_parameters(X, T, n_folds=4,\n",
    "                         structs=[\n",
    "                             #[ [], [] ],\n",
    "                             #[ [], [10] ],\n",
    "                             [[[10, 3, 1]], []],\n",
    "                             #[[[20, 3, 2], [5, 3, 1]], [15]],\n",
    "                             #[[[8, 4, 1]], [10],[5]],\n",
    "                            ],\n",
    "                          methods=['adam','sgd'], # , 'sgd'],\n",
    "                          epochs=[10],\n",
    "                          learning_rates=[0.005], #, 0.1],\n",
    "                          batch_sizes=[10])\n",
    "    print(\"After very run we print the Maximum Percentage validation and Layerinfo for that validation percentage\")\n",
    "    MaxValidation = df.max()['val %']\n",
    "    print(\"Maximum value for Percent_Validation is\",MaxValidation)\n",
    "    MaxvalueIndex = []\n",
    "    MaxvalueIndex = df['val %'].argmax()\n",
    "    Layerinfo5 = df.iloc[MaxvalueIndex]\n",
    "    print('Neural Network parameters for maximum percentage validation')\n",
    "    print(Layerinfo5[0:7])\n",
    "    print(\"We are excluding the test percentage so as to avoid peeking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "1. Adam Optimizer does a give a better peromance than SGD optimizer.\n",
    "2. We fix our optimizer as ADAM from here on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Now we vary number of epochs and keep the rest constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After very run we print the Maximum Percentage validation and Layerinfo for that validation percentage\n",
      "Maximum value for Percent_Validation is 82.6\n",
      "Neural Network parameters for maximum percentage validation\n",
      "structs           [[[10, 3, 1]], []]\n",
      "methods                         adam\n",
      "epochs                            50\n",
      "learning_rates                 0.005\n",
      "batch_sizes                       10\n",
      "train %                         89.1\n",
      "val %                           82.6\n",
      "Name: 47, dtype: object\n",
      "We are excluding the test percentage so as to avoid peeking\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    df = run_these_parameters(X, T, n_folds=4,\n",
    "                         structs=[\n",
    "                             #[ [], [] ],\n",
    "                             #[ [], [10] ],\n",
    "                             [[[10, 3, 1]], []],\n",
    "                             #[[[20, 3, 2], [5, 3, 1]], [15]],\n",
    "                             #[[[8, 4, 1]], [10],[5]],\n",
    "                            ],\n",
    "                          methods=['adam'], # , 'sgd'],\n",
    "                          epochs=[1,10,25,50],\n",
    "                          learning_rates=[0.005], #, 0.1],\n",
    "                          batch_sizes=[10])\n",
    "    print(\"After very run we print the Maximum Percentage validation and Layerinfo for that validation percentage\")\n",
    "    MaxValidation = df.max()['val %']\n",
    "    print(\"Maximum value for Percent_Validation is\",MaxValidation)\n",
    "    MaxvalueIndex = []\n",
    "    MaxvalueIndex = df['val %'].argmax()\n",
    "    Layerinfo6 = df.iloc[MaxvalueIndex]\n",
    "    print('Neural Network parameters for maximum percentage validation')\n",
    "    print(Layerinfo6[0:7])\n",
    "    print(\"We are excluding the test percentage so as to avoid peeking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "1. Increasing the number of epochs does increase validation accuracy significantly.\n",
    "2. But with higher values for number of epochs and lower values for learning_rate, the neural network might keep on searching for better values and might go out of scope from the local minima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Varying batches and keeping other parameters constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After very run we print the Maximum Percentage validation and Layerinfo for that validation percentage\n",
      "Maximum value for Percent_Validation is 85.0\n",
      "Neural Network parameters for maximum percentage validation\n",
      "structs           [[[10, 3, 1]], []]\n",
      "methods                         adam\n",
      "epochs                            50\n",
      "learning_rates                 0.005\n",
      "batch_sizes                      100\n",
      "train %                         91.2\n",
      "val %                           85.0\n",
      "Name: 34, dtype: object\n",
      "We are excluding the test percentage so as to avoid peeking\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    df = run_these_parameters(X, T, n_folds=4,\n",
    "                         structs=[\n",
    "                             #[ [], [] ],\n",
    "                             #[ [], [10] ],\n",
    "                             [[[10, 3, 1]], []],\n",
    "                             #[[[20, 3, 2], [5, 3, 1]], [15]],\n",
    "                             #[[[8, 4, 1]], [10],[5]],\n",
    "                            ],\n",
    "                          methods=['adam'], # , 'sgd'],\n",
    "                          epochs=[50],\n",
    "                          learning_rates=[0.005], #, 0.1],\n",
    "                          batch_sizes=[10,50,100])\n",
    "    print(\"After very run we print the Maximum Percentage validation and Layerinfo for that validation percentage\")\n",
    "    MaxValidation = df.max()['val %']\n",
    "    print(\"Maximum value for Percent_Validation is\",MaxValidation)\n",
    "    MaxvalueIndex = []\n",
    "    MaxvalueIndex = df['val %'].argmax()\n",
    "    Layerinfo7 = df.iloc[MaxvalueIndex]\n",
    "    print('Neural Network parameters for maximum percentage validation')\n",
    "    print(Layerinfo7[0:7])\n",
    "    print(\"We are excluding the test percentage so as to avoid peeking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: \n",
    "1. With in an increase in batch size we see that the validation accuracy increases, but we did not get our best value at batches = 100, this is because a large batch may lead to poor generalization, note that we did want consider our batch size to be the entire dataset, this would gaurantee global minima but would be slower than shorter batched which exhibit faster dynamics.\n",
    "2. The plus point of using a smaller batch is also that it restricts overfitting on the training dataset, which results in poor performance on testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters that work best based on Validation acccuracy\n",
      "structs           [[[10, 3, 1]], []]\n",
      "methods                         adam\n",
      "epochs                            50\n",
      "learning_rates                 0.005\n",
      "batch_sizes                      100\n",
      "train %                         91.2\n",
      "val %                           85.0\n",
      "Name: 34, dtype: object\n",
      "\n",
      "\n",
      "Disscussion : \n",
      "1. With the above parameters we get a validation accuracy of  85.0\n",
      "2. A single convolution layer neural network seems to work best for this case\n",
      "3. A lower learning rate is effective here, contrary to my previous understanding ofincreasing learning leads to convergence quickly,but that is only possible if we have a large number of epochs\n",
      "4. Large values for number of epochs leads to more computational load and can reach saturation quite early on a good neural network structure\n",
      "5. Smaller batch sizes are good for computation and can find good local minima efficiently\n"
     ]
    }
   ],
   "source": [
    "print(\"Parameters that work best based on Validation acccuracy\")\n",
    "print(Layerinfo7[0:7])\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"Disscussion : \") \n",
    "print(\"1. With the above parameters we get a validation accuracy of \",MaxValidation)\n",
    "print(\"2. A single convolution layer neural network seems to work best for this case\")\n",
    "print(\"3. A lower learning rate is effective here, contrary to my previous understanding of\"\n",
    "      \"increasing learning leads to convergence quickly,\"\n",
    "      \"but that is only possible if we have a large number of epochs\")\n",
    "print(\"4. Large values for number of epochs leads to more computational \" \n",
    "      \"load and can reach saturation quite early on a good neural network structure\")\n",
    "print(\"5. Smaller batch sizes are good for computation and can find good local minima efficiently\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train %    83.2\n",
      "val %      81.2\n",
      "test %     77.0\n",
      "Name: 0, dtype: object\n",
      "train %    81.6\n",
      "val %      79.2\n",
      "test %     78.4\n",
      "Name: 7, dtype: object\n",
      "train %    72.7\n",
      "val %      73.2\n",
      "test %     74.4\n",
      "Name: 0, dtype: object\n",
      "train %    79.8\n",
      "val %      80.6\n",
      "test %     76.6\n",
      "Name: 33, dtype: object\n",
      "train %    82.5\n",
      "val %      81.4\n",
      "test %     78.0\n",
      "Name: 6, dtype: object\n",
      "train %    89.1\n",
      "val %      82.6\n",
      "test %     80.2\n",
      "Name: 47, dtype: object\n",
      "train %    91.2\n",
      "val %      85.0\n",
      "test %     81.4\n",
      "Name: 34, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(Layerinfo1[5:])\n",
    "print(Layerinfo2[5:])\n",
    "print(Layerinfo3[5:])\n",
    "print(Layerinfo4[5:])\n",
    "print(Layerinfo5[5:])\n",
    "print(Layerinfo6[5:])\n",
    "print(Layerinfo7[5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disscussion: \n",
    "1. As training accuracy approaches 100% we can see that the difference between Validation accuracy and Test accuracy increases, that is as the training data overfits the difference between validation and test accuracy increases, which implies overfitting a model on the training data is bad for test and validate accuracy.\n",
    "2. We can see that around 80 % Training accuracy we get the difference between validation and testing accuracy to the minimum.\n",
    "3. So making batch size small lowers the risk of overfitting and so we can make the Validation and Test accuracy equal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(Y_classes, T):\n",
    "    class_names = np.unique(T)\n",
    "    table = []\n",
    "    for true_class in class_names:\n",
    "        row = []\n",
    "        for Y_class in class_names:\n",
    "            row.append(100 * np.mean(Y_classes[T == true_class] == Y_class))\n",
    "        table.append(row)\n",
    "    conf_matrix = pandas.DataFrame(table, index=class_names, columns=class_names)\n",
    "    # cf.style.background_gradient(cmap='Blues').format(\"{:.1f} %\")\n",
    "    print('Percent Correct')\n",
    "    return conf_matrix.style.background_gradient(cmap='Blues').format(\"{:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Correct\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_aa270_row0_col0{\n",
       "            background-color:  #94c4df;\n",
       "            color:  #000000;\n",
       "        }#T_aa270_row0_col1,#T_aa270_row1_col2,#T_aa270_row1_col3,#T_aa270_row3_col0{\n",
       "            background-color:  #08306b;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_aa270_row0_col2{\n",
       "            background-color:  #2979b9;\n",
       "            color:  #000000;\n",
       "        }#T_aa270_row0_col3{\n",
       "            background-color:  #eff6fc;\n",
       "            color:  #000000;\n",
       "        }#T_aa270_row1_col0,#T_aa270_row3_col1,#T_aa270_row3_col2,#T_aa270_row3_col3{\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }#T_aa270_row1_col1{\n",
       "            background-color:  #3787c0;\n",
       "            color:  #000000;\n",
       "        }#T_aa270_row2_col0{\n",
       "            background-color:  #206fb4;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_aa270_row2_col1{\n",
       "            background-color:  #6aaed6;\n",
       "            color:  #000000;\n",
       "        }#T_aa270_row2_col2{\n",
       "            background-color:  #c1d9ed;\n",
       "            color:  #000000;\n",
       "        }#T_aa270_row2_col3{\n",
       "            background-color:  #e7f0fa;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_aa270_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >divide</th>        <th class=\"col_heading level0 col1\" >minus</th>        <th class=\"col_heading level0 col2\" >plus</th>        <th class=\"col_heading level0 col3\" >times</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_aa270_level0_row0\" class=\"row_heading level0 row0\" >divide</th>\n",
       "                        <td id=\"T_aa270_row0_col0\" class=\"data row0 col0\" >29.5</td>\n",
       "                        <td id=\"T_aa270_row0_col1\" class=\"data row0 col1\" >8.4</td>\n",
       "                        <td id=\"T_aa270_row0_col2\" class=\"data row0 col2\" >60.2</td>\n",
       "                        <td id=\"T_aa270_row0_col3\" class=\"data row0 col3\" >1.8</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_aa270_level0_row1\" class=\"row_heading level0 row1\" >minus</th>\n",
       "                        <td id=\"T_aa270_row1_col0\" class=\"data row1 col0\" >3.0</td>\n",
       "                        <td id=\"T_aa270_row1_col1\" class=\"data row1 col1\" >7.2</td>\n",
       "                        <td id=\"T_aa270_row1_col2\" class=\"data row1 col2\" >74.1</td>\n",
       "                        <td id=\"T_aa270_row1_col3\" class=\"data row1 col3\" >15.7</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_aa270_level0_row2\" class=\"row_heading level0 row2\" >plus</th>\n",
       "                        <td id=\"T_aa270_row2_col0\" class=\"data row2 col0\" >53.0</td>\n",
       "                        <td id=\"T_aa270_row2_col1\" class=\"data row2 col1\" >6.6</td>\n",
       "                        <td id=\"T_aa270_row2_col2\" class=\"data row2 col2\" >38.0</td>\n",
       "                        <td id=\"T_aa270_row2_col3\" class=\"data row2 col3\" >2.4</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_aa270_level0_row3\" class=\"row_heading level0 row3\" >times</th>\n",
       "                        <td id=\"T_aa270_row3_col0\" class=\"data row3 col0\" >69.3</td>\n",
       "                        <td id=\"T_aa270_row3_col1\" class=\"data row3 col1\" >4.8</td>\n",
       "                        <td id=\"T_aa270_row3_col2\" class=\"data row3 col2\" >24.7</td>\n",
       "                        <td id=\"T_aa270_row3_col3\" class=\"data row3 col3\" >1.2</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2b302b32a60>"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for Xtrain, Ttrain,Xval,Tval, Xtest, Ttest in mlfuncs.generate_partitions(X, T, n_folds, validation=True, shuffle=True, classification=True):\n",
    "    break\n",
    "df = run_these_parameters(X, T, n_folds=4,\n",
    "                         structs=[\n",
    "                            [[[10, 3, 1]], []],\n",
    "                            ],\n",
    "                          methods=['adam'], # , 'sgd'],\n",
    "                          epochs=[50],\n",
    "                          learning_rates=[0.005], #, 0.1],\n",
    "                          batch_sizes=[50])\n",
    "confusion_matrix(cnn.use(Xtest)[0], Ttest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion:\n",
    "1. For 29.5% times we get divide value accurately in test data, 60.2 % times we get divide as plus in test data,8.4% times we get divide as minus in test data and 1.8% time we get divide as times in test data.\n",
    "2. For 7.2% times we minus accurately in test data,74.1% times we get minus as plus in test data, 15.7% times we minus as times in test data and 3.0% times we get minus as divide in test data.\n",
    "3. For 53.0% times we get plus as divide in test data, 38.0% times we get plus accurately in test data, 6.6% times we get plus as minus in test data,2.4% times we plus as times in test data.\n",
    "4. 69.3% times we get times as divide in test data, 4.8% times we get times as minus in test data, 24.7% times we get times as plus in  test data and 1.2% times we times accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimentation for methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_each_class = 500\n",
    "X, T = make_images(n_each_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st iteration output\n",
      "After very run we print the Maximum Percentage validation and Layerinfo for that validation percentage\n",
      "Maximum value for Percent_Validation is 83.0\n",
      "Neural Network parameters for maximum percentage validation\n",
      "structs           [[[10, 3, 1]], []]\n",
      "methods                         adam\n",
      "epochs                            50\n",
      "learning_rates                 0.005\n",
      "batch_sizes                       50\n",
      "train %                         93.0\n",
      "val %                           83.0\n",
      "test %                          78.6\n",
      "Name: 8, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"1st iteration output\")\n",
    "for i in range(1):\n",
    "    df = run_these_parameters(X, T, n_folds=4,\n",
    "                         structs=[\n",
    "                             #[ [], [] ],\n",
    "                             #[ [], [10] ],\n",
    "                             [[[10, 3, 1]], []],\n",
    "                             #[[[20, 3, 2], [5, 3, 1]], [15]],\n",
    "                             #[[[8, 4, 1]], [10],[5]],\n",
    "                            ],\n",
    "                          methods=['adam'], # , 'sgd'],\n",
    "                          epochs=[50],\n",
    "                          learning_rates=[0.005], #, 0.1],\n",
    "                          batch_sizes=[50])\n",
    "    print(\"After very run we print the Maximum Percentage validation and Layerinfo for that validation percentage\")\n",
    "    MaxValidation = df.max()['val %']\n",
    "    print(\"Maximum value for Percent_Validation is\",MaxValidation)\n",
    "    MaxvalueIndex = []\n",
    "    MaxvalueIndex = df['val %'].argmax()\n",
    "    Layerinfo8 = df.iloc[MaxvalueIndex]\n",
    "    print('Neural Network parameters for maximum percentage validation')\n",
    "    print(Layerinfo8)\n",
    "    #print(\"We are excluding the test percentage so as to avoid peeking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st iteration output\n",
      "After very run we print the Maximum Percentage validation and Layerinfo for that validation percentage\n",
      "Maximum value for Percent_Validation is 68.8\n",
      "Neural Network parameters for maximum percentage validation\n",
      "structs           [[[10, 3, 1]], []]\n",
      "methods                          sgd\n",
      "epochs                            50\n",
      "learning_rates                 0.005\n",
      "batch_sizes                       50\n",
      "train %                         66.5\n",
      "val %                           68.8\n",
      "test %                          64.2\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"1st iteration output\")\n",
    "for i in range(1):\n",
    "    df = run_these_parameters(X, T, n_folds=4,\n",
    "                         structs=[\n",
    "                             #[ [], [] ],\n",
    "                             #[ [], [10] ],\n",
    "                             [[[10, 3, 1]], []],\n",
    "                             #[[[20, 3, 2], [5, 3, 1]], [15]],\n",
    "                             #[[[8, 4, 1]], [10],[5]],\n",
    "                            ],\n",
    "                          methods=['sgd'], # , 'sgd'],\n",
    "                          epochs=[50],\n",
    "                          learning_rates=[0.005], #, 0.1],\n",
    "                          batch_sizes=[50])\n",
    "    print(\"After very run we print the Maximum Percentage validation and Layerinfo for that validation percentage\")\n",
    "    MaxValidation = df.max()['val %']\n",
    "    print(\"Maximum value for Percent_Validation is\",MaxValidation)\n",
    "    MaxvalueIndex = []\n",
    "    MaxvalueIndex = df['val %'].argmax()\n",
    "    Layerinfo9 = df.iloc[MaxvalueIndex]\n",
    "    print('Neural Network parameters for maximum percentage validation')\n",
    "    print(Layerinfo9)\n",
    "    #print(\"We are excluding the test percentage so as to avoid peeking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion:\n",
    "1. From the above two iterations we can see that the ADAM performs better with a convolutional neural network than a SGD optimizer.\n",
    "2. As we can also see that as the training accuracy approaches 100% the difference between our test and validation accuracy is increasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2nd iteration output\n",
      "After very run we print the Maximum Percentage validation and Layerinfo for that validation percentage\n",
      "Maximum value for Percent_Validation is 84.0\n",
      "Neural Network parameters for maximum percentage validation\n",
      "structs           [[], []]\n",
      "methods               adam\n",
      "epochs                  30\n",
      "learning_rates        0.08\n",
      "batch_sizes             10\n",
      "train %               98.1\n",
      "val %                 84.0\n",
      "test %                80.2\n",
      "Name: 10, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"2nd iteration output\")\n",
    "for i in range(1):\n",
    "    df = run_these_parameters(X, T, n_folds=4,\n",
    "                         structs=[\n",
    "                             [ [], [] ],\n",
    "                             #[ [], [10] ],\n",
    "                             #[[[10, 3, 1]], []],\n",
    "                             #[[[20, 3, 2], [5, 3, 1]], [15]],\n",
    "                             #[[[8, 4, 1]], [10],[5]],\n",
    "                            ],\n",
    "                          methods=['adam'], # , 'sgd'],\n",
    "                          epochs=[30],\n",
    "                          learning_rates=[0.08], #, 0.1],\n",
    "                          batch_sizes=[10])\n",
    "    print(\"After very run we print the Maximum Percentage validation and Layerinfo for that validation percentage\")\n",
    "    MaxValidation = df.max()['val %']\n",
    "    print(\"Maximum value for Percent_Validation is\",MaxValidation)\n",
    "    MaxvalueIndex = []\n",
    "    MaxvalueIndex = df['val %'].argmax()\n",
    "    Layerinfo9 = df.iloc[MaxvalueIndex]\n",
    "    print('Neural Network parameters for maximum percentage validation')\n",
    "    print(Layerinfo9)\n",
    "    #print(\"We are excluding the test percentage so as to avoid peeking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2nd iteration output\n",
      "After very run we print the Maximum Percentage validation and Layerinfo for that validation percentage\n",
      "Maximum value for Percent_Validation is 73.6\n",
      "Neural Network parameters for maximum percentage validation\n",
      "structs           [[], []]\n",
      "methods                sgd\n",
      "epochs                  30\n",
      "learning_rates        0.08\n",
      "batch_sizes             10\n",
      "train %               73.5\n",
      "val %                 73.6\n",
      "test %                67.6\n",
      "Name: 5, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"2nd iteration output\")\n",
    "for i in range(1):\n",
    "    df = run_these_parameters(X, T, n_folds=4,\n",
    "                         structs=[\n",
    "                             [ [], [] ],\n",
    "                             #[ [], [10] ],\n",
    "                             #[[[10, 3, 1]], []],\n",
    "                             #[[[20, 3, 2], [5, 3, 1]], [15]],\n",
    "                             #[[[8, 4, 1]], [10],[5]],\n",
    "                            ],\n",
    "                          methods=['sgd'], # , 'sgd'],\n",
    "                          epochs=[30],\n",
    "                          learning_rates=[0.08], #, 0.1],\n",
    "                          batch_sizes=[10])\n",
    "    print(\"After very run we print the Maximum Percentage validation and Layerinfo for that validation percentage\")\n",
    "    MaxValidation = df.max()['val %']\n",
    "    print(\"Maximum value for Percent_Validation is\",MaxValidation)\n",
    "    MaxvalueIndex = []\n",
    "    MaxvalueIndex = df['val %'].argmax()\n",
    "    Layerinfo9 = df.iloc[MaxvalueIndex]\n",
    "    print('Neural Network parameters for maximum percentage validation')\n",
    "    print(Layerinfo9)\n",
    "    #print(\"We are excluding the test percentage so as to avoid peeking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion:\n",
    "1. We can see here that a lower batch size lowers computational load and increases time response.\n",
    "2. ADAM performs even with a linear model for neural network structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"multiple iteration output\")\n",
    "for i in range(1):\n",
    "    df = run_these_parameters(X, T, n_folds=4,\n",
    "                         structs=[\n",
    "                             [ [], [] ],\n",
    "                             [ [], [10] ],\n",
    "                             [[[10, 3, 1]], []],\n",
    "                             [[[20, 3, 2], [5, 3, 1]], [15]],\n",
    "                             [[[8, 4, 1]], [10],[5]],\n",
    "                            ],\n",
    "                          methods=['adam','sgd'], # , 'sgd'],\n",
    "                          epochs=[10,20,30],\n",
    "                          learning_rates=[0.04,0.08,0.1], #, 0.1],\n",
    "                          batch_sizes=[5,10,15])\n",
    "    print(\"After very run we print the Maximum Percentage validation and Layerinfo for that validation percentage\")\n",
    "    MaxValidation = df.max()['val %']\n",
    "    print(\"Maximum value for Percent_Validation is\",MaxValidation)\n",
    "    MaxvalueIndex = []\n",
    "    MaxvalueIndex = df['val %'].argmax()\n",
    "    Layerinfo9 = df.iloc[MaxvalueIndex]\n",
    "    print('Neural Network parameters for maximum percentage validation')\n",
    "    print(Layerinfo9)\n",
    "    #print(\"We are excluding the test percentage so as to avoid peeking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T20:44:33.927450Z",
     "start_time": "2020-10-16T20:44:33.925092Z"
    }
   },
   "source": [
    "# Grading\n",
    "\n",
    "(UPDATED Oct. 21, 9:35am, tolerance on accuracies is now larger) Download [A4grader.tar](https://www.cs.colostate.edu/~anderson/cs545/notebooks/A4grader.tar), extract `A4grader.py` before running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-18T14:52:02.691904Z",
     "start_time": "2021-10-18T14:51:57.734208Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================= Code Execution =======================\n",
      "\n",
      "Extracting python code from notebook named 'Shetty-A4.ipynb' and storing in notebookcode.py\n",
      "Removing all statements that are not function or class defs or import statements.\n",
      "\n",
      "===========================================================================================\n",
      "Testing:\n",
      "\n",
      "    def make_images(n_each_class):\n",
      "        images = np.zeros((n_each_class * 2, 20, 20))  # nSamples, rows, columns\n",
      "        radii = 3 + np.random.randint(10 - 5, size=(n_each_class * 2, 1))\n",
      "        centers = np.zeros((n_each_class * 2, 2))\n",
      "        for i in range(n_each_class * 2):\n",
      "            r = radii[i, 0]\n",
      "            centers[i, :] = r + 1 + np.random.randint(18 - 2 * r, size=(1, 2))\n",
      "            x = int(centers[i, 0])\n",
      "            y = int(centers[i, 1])\n",
      "            if i < n_each_class:\n",
      "                # squares\n",
      "                images[i, x - r:x + r, y + r] = 1.0\n",
      "                images[i, x - r:x + r, y - r] = 1.0\n",
      "                images[i, x - r, y - r:y + r] = 1.0\n",
      "                images[i, x + r, y - r:y + r + 1] = 1.0\n",
      "            else:\n",
      "                # diamonds\n",
      "                images[i, range(x - r, x), range(y, y + r)] = 1.0\n",
      "                images[i, range(x - r, x), range(y, y - r, -1)] = 1.0\n",
      "                images[i, range(x, x + r + 1), range(y + r, y - 1, -1)] = 1.0\n",
      "                images[i, range(x, x + r), range(y - r, y)] = 1.0\n",
      "        T = np.array(['square'] * n_each_class + ['diamond'] * n_each_class).reshape(-1, 1)\n",
      "        n, r, c = images.shape\n",
      "        images = images.reshape(n, r, c, 1)  # add channel dimsension\n",
      "        return images, T\n",
      "\n",
      "    np.random.seed(4200)\n",
      "\n",
      "    n_each_class = 10\n",
      "    Xtrain, Ttrain = make_images(n_each_class * 2)\n",
      "    Xval, Tval = make_images(n_each_class)\n",
      "    Xtest, Ttest = make_images(n_each_class)\n",
      "    print(Xtrain.shape, Ttrain.shape, Xval.shape, Tval.shape, Xtest.shape, Ttest.shape)\n",
      "\n",
      "    struct = [ [[2, 5, 1]], [5] ]\n",
      "    n_epochs = 20\n",
      "    method= 'adam'\n",
      "    learning_rate = 0.01\n",
      "    batch_size = 5\n",
      "\n",
      "    result = train_this_partition(Xtrain, Ttrain, Xval, Tval, Xtest, Ttest,\n",
      "                                   struct, n_epochs, method, learning_rate, batch_size)\n",
      "\n",
      "(40, 20, 20, 1) (40, 1) (20, 20, 20, 1) (20, 1) (20, 20, 20, 1) (20, 1)\n",
      "\n",
      "---  20 / 20 points. train_this_partition correctly returns\n",
      " [(((2, 5, 1),), (5,)), 'adam', 20, 0.01, 5, 90.0, 70.0, 70.0]\n",
      "\n",
      "===========================================================================================\n",
      "Testing\n",
      "\n",
      "    np.random.seed(4200)\n",
      "\n",
      "    n_each_class = 10\n",
      "    Xtrain, Ttrain = make_images(n_each_class * 2)\n",
      "    Xval, Tval = make_images(n_each_class)\n",
      "    Xtest, Ttest = make_images(n_each_class)\n",
      "    print(Xtrain.shape, Ttrain.shape, Xval.shape, Tval.shape, Xtest.shape, Ttest.shape)\n",
      "\n",
      "    structs = [ [[], []],\n",
      "                [[], [10]],\n",
      "                [[[4, 5, 1], [5, 3, 1]], [5]]\n",
      "               ]\n",
      "    n_epochs = [10, 20]\n",
      "    methods= ['adam']\n",
      "    learning_rates = [0.01, 0.1]\n",
      "    batch_sizes = [5]\n",
      "\n",
      "    results = []\n",
      "    for struct in structs:\n",
      "        for epochs in n_epochs:\n",
      "            for method in methods:\n",
      "                for learning_rate in learning_rates:\n",
      "                    for batch_size in batch_sizes:\n",
      "                    \n",
      "                        # This next for loop simulates how you will use generate_partitions\n",
      "                        # in run_these_parameters\n",
      "                        for Xtrain, Ttrain, Xval, Tval, Xtest, Ttest in [[Xtrain, Ttrain, Xval, Tval, Xtest, Ttest]]:\n",
      "                            result = train_this_partition(Xtrain, Ttrain, Xval, Tval, Xtest, Ttest,\n",
      "                                                          struct, epochs, method, learning_rate, batch_size)\n",
      "                            results.append(result)\n",
      "\n",
      "(40, 20, 20, 1) (40, 1) (20, 20, 20, 1) (20, 1) (20, 20, 20, 1) (20, 1)\n",
      "\n",
      "--- 20 / 20 points. train_this_partition correctly returns\n",
      "[((), ()), 'adam', 10, 0.01, 5, 100.0, 75.0, 90.0]\n",
      "[((), ()), 'adam', 10, 0.1, 5, 100.0, 70.0, 85.0]\n",
      "[((), ()), 'adam', 20, 0.01, 5, 100.0, 75.0, 90.0]\n",
      "[((), ()), 'adam', 20, 0.1, 5, 100.0, 70.0, 85.0]\n",
      "[((), (10,)), 'adam', 10, 0.01, 5, 100.0, 65.0, 85.0]\n",
      "[((), (10,)), 'adam', 10, 0.1, 5, 100.0, 65.0, 85.0]\n",
      "[((), (10,)), 'adam', 20, 0.01, 5, 100.0, 65.0, 80.0]\n",
      "[((), (10,)), 'adam', 20, 0.1, 5, 100.0, 65.0, 80.0]\n",
      "[(((4, 5, 1), (5, 3, 1)), (5,)), 'adam', 10, 0.01, 5, 85.0, 70.0, 70.0]\n",
      "[(((4, 5, 1), (5, 3, 1)), (5,)), 'adam', 10, 0.1, 5, 92.5, 60.0, 75.0]\n",
      "[(((4, 5, 1), (5, 3, 1)), (5,)), 'adam', 20, 0.01, 5, 92.5, 65.0, 75.0]\n",
      "[(((4, 5, 1), (5, 3, 1)), (5,)), 'adam', 20, 0.1, 5, 100.0, 65.0, 75.0]\n",
      "\n",
      "===========================================================================================\n",
      "Testing\n",
      "\n",
      "    np.random.seed(4200)\n",
      "\n",
      "    n_each_class = 40\n",
      "    X, T = make_images(n_each_class * 2)\n",
      "\n",
      "    structs = [ [[], []],\n",
      "                [[], [10]],\n",
      "                [[[4, 5, 1], [5, 3, 1]], [5]]\n",
      "               ]\n",
      "    methods= ['adam']\n",
      "    n_epochs = [10]\n",
      "    learning_rates = [0.01, 0.1]\n",
      "    batch_sizes = [-1, 5]  # -1 means train on all training samples, not multiple batches\n",
      "    n_folds = 3\n",
      "    \n",
      "    print('This may take several minutes...')\n",
      "    \n",
      "    df = run_these_parameters(X, T, n_folds,\n",
      "                              structs, methods, n_epochs, learning_rates, batch_sizes)\n",
      "\n",
      "    # Here is a function you can use to print all columns and rows of a DataFrame\n",
      "    def print_df(df):\n",
      "        with pandas.option_context('display.width', 100,\n",
      "                                   'display.max_rows', None,\n",
      "                                   'display.max_columns', None):\n",
      "            print(df)\n",
      "\n",
      "This may take several minutes...\n",
      "\n",
      "-- 10 / 10 points. DataFrame returns has correct shape, (72, 8)\n",
      "\n",
      "--- 20 / 20 points. Returned DataFrame has correct percent means of [93.15857753 76.29159035 76.44803114] :\n",
      "\n",
      "============================================================\n",
      "C:\\Users\\vishalsh\\Downloads\\A4 Execution Grade is 70 / 70\n",
      "============================================================\n",
      "\n",
      "\n",
      "__ / 5 points.  Discuss what you observe after each call to run_these_parameters with\n",
      "         at least two sentences for each run.\n",
      "\n",
      "__ / 5 points.  Discuss which parameter values seem to work the best according to\n",
      "         the validation accuracy.\n",
      "\n",
      "__ / 5 points.  Discuss how well the validation and test accuracies equal each other\n",
      "          and what you might do to make them more equal.\n",
      "\n",
      "__ / 5 points.  Show and discuss a confusion matrix on test data for a network trained\n",
      "          with your best parameter values.\n",
      "\n",
      "__ / 10 points.  For each method, try various hidden layer structures, learning rates,\n",
      "          and numbers of epochs. Use the validation percent accuracy to pick the best\n",
      "          hidden layers, learning rates and numbers of epochs for each method. Report\n",
      "          training, validation and test accuracy for your best validation results\n",
      "          for each of the three methods.\n",
      "\n",
      "\n",
      "======================================================================\n",
      "C:\\Users\\vishalsh\\Downloads\\A4 Results and Discussion Grade is ___ / 30\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "C:\\Users\\vishalsh\\Downloads\\A4 FINAL GRADE is  _  / 100\n",
      "======================================================================\n",
      "\n",
      "Extra Credit: \n",
      "Repeat the above experiment using a convolutional neural network defined in Pytorch.\n",
      "Implement this yourself by directly calling torch.nn functions.\n",
      "\n",
      "\n",
      " C:\\Users\\vishalsh\\Downloads\\A4 EXTRA CREDIT is 0 / 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run -i A4grader.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Credit\n",
    "\n",
    "Repeat the above experiment using a convolutional neural network defined in `Pytorch`.  Implement this yourself by directly calling `torch.nn` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
